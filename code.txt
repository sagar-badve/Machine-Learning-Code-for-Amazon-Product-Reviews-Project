##################################################################################################################################
#Classification using Logistic Regression Classifier
import os
import pandas as pd
import sklearn.metrics as metrics
from sklearn.linear_model import LogisticRegression
from sklearn.cross_validation import train_test_split

os.chdir("directory_path ")
data = pd.read_csv("filename.csv", header=0, sep=",") 
columns = data.columns
#target = data[columns[14]]
target = data[columns[12]]
predictors = data[columns[1:11]]

train_X, test_X, train_Y, test_Y =  train_test_split(predictors, target, test_size = 0.3, random_state = 99)
classifier = LogisticRegression()
classifier.fit(train_X, train_Y)
predicted = classifier.predict(test_X)

list1 = []    
for i in range(10):
    print("\n\n*****LOGISTIC REGRESSION RESULTS*****")
    print("\nAccuracy: " + str(metrics.accuracy_score(test_Y, predicted)))
    print("\nThe confusion matrix is: ")
    print(metrics.confusion_matrix(test_Y, predicted))
    print("\nThe classification report is: ")
    print(metrics.classification_report(test_Y, predicted,  target_names = ["bad", "good"]))
    #print(metrics.classification_report(test_Y, predicted,  target_names = ["2", "3", "4", "5", "6","7", "8", "9", "10"]))  
    list1.append(metrics.accuracy_score(test_Y, predicted))

average = sum(list1)/10
print(average)

##################################################################################################################################
#Classification using Random Forest Classifier
import os
import pandas as pd
import sklearn.metrics as metrics
from sklearn.ensemble import RandomForestClassifier
from sklearn.cross_validation import train_test_split

os.chdir("directory_path ")
data = pd.read_csv("filename.csv", header=0, sep=",") 
columns = data.columns
#target = data[columns[14]]
target = data[columns[12]]
predictors = data[columns[1:11]]
train_X, test_X, train_Y, test_Y =  train_test_split(predictors, target, test_size = 0.3, random_state = 9)

list1 = []    
for i in range(10):    
    classifier = RandomForestClassifier(n_estimators=700)
    #train the model
    classifier.fit(train_X, train_Y)
    predicted = classifier.predict(test_X)
    print("\n\n*****RANDOM FOREST RESULTS*****")
    print("\nAccuracy: " + str(metrics.accuracy_score(test_Y, predicted)))
    print("\nThe confusion matrix is: ")
    print(metrics.confusion_matrix(test_Y, predicted))
    print("\nThe classification report is: ")
    #print(metrics.classification_report(test_Y, predicted,  target_names = ["2", "3", "4", "5", "6","7", "8", "9", "10"]))
    print(metrics.classification_report(test_Y, predicted,  target_names = ["bad", "good"]))
    list1.append(metrics.accuracy_score(test_Y, predicted))

average = sum(list1)/10
print(average)

##################################################################################################################################
#Classification using Extra Trees Classifier
import os
import pandas as pd
import sklearn.metrics as metrics
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.cross_validation import train_test_split

os.chdir("directory_path ")

data = pd.read_csv("filename.csv", header=0, sep=",") 
columns = data.columns
#target = data[columns[14]]
predictors = data[columns[1:11]]
target = data[columns[12]]

train_X, test_X, train_Y, test_Y =  train_test_split(predictors, target, test_size = 0.3, random_state = 9)     
classifier = ExtraTreesClassifier(n_estimators=500)
classifier.fit(train_X, train_Y)
predicted = classifier.predict(test_X)

list1 = []    
for i in range(10):
    print("\n\n*****EXTRA TREES RESULTS*****")
    print("\nAccuracy: " + str(metrics.accuracy_score(test_Y, predicted)))
    print("\nThe confusion matrix is: ")
    print(metrics.confusion_matrix(test_Y, predicted))
    print("\nThe classification report is: ")
    print(metrics.classification_report(test_Y, predicted,  target_names = ["bad", "good"]))
    #print(metrics.classification_report(test_Y, predicted,  target_names = ["2", "3", "4", "5", "6","7", "8", "9", "10"]))
    list1.append(metrics.accuracy_score(test_Y, predicted))

average = sum(list1)/10
print(average)

##################################################################################################################################
#Prediction using Linear Regression

import os
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import scale

os.chdir("directory_path ")

data = pd.read_csv("filename.csv", header=0, sep=",") 
columns = data.columns
target = data[columns[14]]
predictors = data[columns[1:11]]
     
predictors = scale(predictors)
classifier = LinearRegression()

classifier.fit(predictors, target)

r2 =classifier.score(predictors,target)
print("R=Squared: ", r2)

coefficients = zip(data[columns[1:11]], classifier.coef_)
for i in coefficients:
    print(i)

####################################################################################################################################
#Feature selection using SelectKBest

import os
import pandas as pd
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

os.chdir("directory_path ")

data = pd.read_csv("filename.csv")
y = data['target_column']
columns = data.columns
X = data[columns[2:12]]

x_new = SelectKBest(chi2, k='all')
x_new.fit_transform(X,y)


for i in x_new.scores_:
    print(float(i))
	
####################################################################################################################################
